---
title: Kenyan Household Bands Classifier
description: Predicting the Household Economic Bands Into Which University Students Fall for Award of Financial Support from the Kenyan Government.
author: 
  - name: Cornelius Tanui
    url: https://corneliustanui.rbind.io/
date: '2024-09-06'

format: 
  html: 
    fontfamily: libertinus
    fontsize: 12pt
    code-fold: true
    html-math-method: katex
    link-citations: true
    number-sections: true

slug: classification
categories: [R, Classification, Prediction, MTI]
---

```{r chunk options, include = FALSE}

knitr::opts_chunk$set(warning = FALSE,
                      message = FALSE)

```

![Image source: Imagine Art](ImagineArt_University_Students_in_Kenya.png){fig-alt="Statistical Data simulation" width="80%" height="100%"}

# University Funding in Kenya

## My Shallow Thoughts on MTI {#sec-shallow}

When I first heard of MTI, my immediate thought was that the government of Kenya had finally embraced Artificial Intelligence on a larger scale and decided to award university students scholarships based on economic bands decided by some novel AI algorithm. Think, a combination of classification algorithms of 'high compute, high repute'. A pleasant thought, right? No.

No because, later on, I searched for MTI online and found out that it stands for 'means testing instrument', and if you are deep into data, you would think 'means' is hereby used to denote average. See, 'testing of means' is not remotely uncommon, we come across it all the time in data analytics. T-test is a test of means. However, 'means' in the context of MTI stands for resources, or assets', that a student has access to that could be used to fund their higher education. ‘Means' can be a confusing word. 'Means of transport', ‘by all means’, etc.

As it turned out, MTI is a widely used concept in the education and social protection sectors, and I was embarrassingly waaay off in thinking that it had something to do with statistical averages.

I was waaay off in yet, yet again, in a different aspect -- the students joining university in September, 2024 as first-years/freshmen had never been banded before, and therefore, there would be no training data for my imagined AI model! This is the first time banding is happening in Kenya, as regards university funding, so maybe, there will be (enough) data to train a model in 2025, so that the freshmen of 2025 will have successfully been banded by AI.

## Background to MTI

Globally, MTI has been around for a while now, with the first documented use in 1930s involving provision of relief to households by governments. If a home was deemed able to support itself by the source of income it had, the the government benefits were stopped or reduced[^1]. MTI has since been heavily employed in the social protection to provide targeted anti-poverty benefits to households, civil legal aid to individuals[^2], communities, and geographies. The obvious reason for preference of MTI to universal provision of support -- such as universal basic income -- is that MTI offers the support to targeted beneficiaries, because with the universal approach, there may be recipients who do not genuinely require it[^3].

[^1]: van Oorschot, W. J. H., & Schell, J. (1991). Means-testing in Europe: A growing concern. In M. Adler, C. Bell, J. Clasen, & A. Sinfield (Eds.), The sociology of social security (pp. 187-211). (Edinburgh education and society series). Edinburgh University Press.

[^2]: https://www.gov.uk/guidance/criminal-legal-aid-means-testing

[^3]: Brown, C., Ravallion, M., & Van de Walle, D. (2016). A poor means test. Econometric targeting in Africa. The World Bank.

In Kenya, MTI has been used for a long time to identify households in marginalized communities that are eligible for benefit from cash transfers[^4] under the National Safety Net Programmes (NSNP). One such safety programme is the Hunger Safety Net Programme (HSNP) that supports old persons, orphans and vulnerable children, and persons with severe disability.

[^4]: Villa, Juan M. \[2016\] A harmonised proxy means test for Kenya’s National Safety Net programme. GDI Working Paper 2016-003. Manchester: The University of Manchester.

Literature indicates that MTI has worked successfully so far in Kenya as implemented under NSNP, yet it is not without shortcomings. For example, the popular controversy around it is, it discourages the target population from engaging in financial savings[^5], consequently promoting poverty, a concept known as poverty trap[^6]. MTI sustained an unmitigated uproar over it's banding inaccuracy[^7] that led to placement of students from poor backgrounds into higher bands that require them to dig deep into their pockets to fill the gap, pockets which they either do not have, or are torn. The bands range from 1 (least able) to 5 (most able.)

[^5]: Elizabeth T. Powers,Does means-testing welfare discourage saving? evidence from a change in AFDC policy in the United States, Journal of Public Economics, Volume 68, Issue 1, 1998, Pages 33-53, ISSN 0047-2727, https://doi.org/10.1016/S0047-2727(97)00087-X. (https://www.sciencedirect.com/science/article/pii/S004727279700087X)

[^6]: Kraay, Aart, and David McKenzie. 2014. "Do Poverty Traps Exist? Assessing the Evidence." Journal of Economic Perspectives, 28 (3): 127–48.

[^7]: https://www.citizen.digital/news/govt-explains-why-many-students-miss-out-on-scholarships-under-the-new-funding-model-n348207

Under the hood, MTI is mainly a regression model -- such as a tobit model -- that aggregates various variables together and provides a value^3^ which is then compared to a threshold that determines whether the candidate qualifies for the benefit, or does not. Principal components analysis models have also been deployed to this cause^4^.

Now, let us explore how a machine learning (ML) classifier could be used as an alternative to MTI to award financial support to university students in Kenya.

# ML Approach to Household Banding

It goes without saying that a student requires a couple of lessons before sitting an exam, so does a ML model require massive -- yet meticulous -- training before it can be deployed for use, as noted in @sec-shallow.

It is not too clear how and which factors were considered to create the 5 bands, although gross family income, geographical location poverty probability index, special circumstances such as orphans and students with disability, number of dependents, program costs, and gender are some of the variables that have been mentioned[^8]. Because I do not have readily available data covering these variables, I am going to simulate them and use R[^9], [{tidyverse}](https://https://www.tidyverse.org//), [{tidymodels}](https://www.tidymodels.org/) and other R packages to develop a data processing, modelling, and prediction pipeline using a ML multi-class classification (MCC)[^10] model of our choice. Note that the outcome should be in discrete ordinal scale.

[^8]: https://kafu.ac.ke/images/2022/Academics/nfm/NEW_FUNDING_MODEL\_-\_6TH_AUGUST_2024.pdf

[^9]: R Core Team (2021). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.

[^10]: Kook, L., Herzog, L., Hothorn, T., Dürr, O., & Sick, B. (2022). Deep and interpretable regression models for ordinal outcomes. Pattern Recognition, 122, 108263.

## Data Simulation

Simulation of these data is outside the scope of this article and is [covered in my other post](https://corneliustanui.rbind.io/content/posts/Simulation_2024-09-12/).

The table below shows the properties of the variables are;

| Variable                              | Data type | Distribution      |
|:--------------------------------------|:----------|:------------------|
| Bands                                 | Ordinal   | Multinomial       |
| Gross family income                   | x ∈ ℝ^+^  | Negative Binomial |
| Geographical location                 | Nominal   | Uniform           |
| Poverty probability index             | x ∈ ℝ^+^  | Skewed Normal     |
| Special circumstances such as orphans | Binary    | Binomial          |
| Students with disability              | Binary    | Binomial          |
| Number of dependents                  | x ∈ ℕ^+^  | Poisson           |
| Program costs                         | x ∈ ℝ^+^  | Skewed Normal     |
| Gender                                | Nominal   | Multinomial       |

: Properties of variables {#tbl-properties .striped .hover .primary .bordered}

## Descrpitive Analysis

::: {.callout-important appearance="default" collapse="false"}
## Disclaimer!

The data is **simulated**, and therefore substantially differs with the actual scenario! The data is meant for learning purposes only, and the statistical estimates reported MUST NOT be taken as true reflection of the real-word situation.
:::

```{r load packages}

## load packages
library(tidyverse)  # data processing packages
library(tidymodels) # model definition packages
library(parsnip)    # model manipulation functions

library(glmnet)     # model processing engine
# library(spark)      # model processing engine
library(keras)      # model processing engine (requires package tensorflow)
library(tensorflow) # The Python Module needs to be installed
library(nnet)       # model processing engine
library(brulee)     # model processing engine (requires libtorch distro of PyTorch)

```

The simulated data looks like this;

```{r the data}

# table display setup
#| label: tbl-simulated_data .striped .hover .primary .bordered
#| tbl-cap: "Simulated data"
#| tbl-cap-location: bottom 

# load data
simulated_data <- readRDS(here::here("./Data/simulated_data.rds"))

# view data (printed on your browser)
knitr::kable(head(x = simulated_data, n = 5))

```

## Model Creation

For a start, we shall define the the model pipeline using the conventional *tidymodels* steps, and specify *keras* as the engine. Later on we will try other engines such as *brulee*, *glmnet*, and *nnet*.

```{r Model Creation}

## create training and testing sets
# set seed for reproducibility
set.seed(44)
data_split <- initial_split(simulated_data, prop = 0.75)

# 75% of records
train_data <- training(data_split) 

# 25% of records
test_data  <- testing(data_split)

# create the null model
multinom_reg_keras_spec <-
  multinom_reg(
    mode = "classification",
    penalty = NULL,
    mixture = NULL) |>
  set_engine('keras')

# create the recipe
multinom_recipe <- 
  
  # specify the outcome variable
  recipe(Bands ~ ., data = train_data) |>
  
  # specify predictors to be one-hot-encoded
  step_dummy(GeographicalLocation, Gender, Orphans, Disability) |>
  
  # center all normally distributed predictors  
  step_center(GrossFamilyIncome, PovertyProbabilityIndex, NumberOfDependents, ProgramCostsKES) |>
  
  # scale all normally distributed predictors 
  step_scale(GrossFamilyIncome, PovertyProbabilityIndex, NumberOfDependents, ProgramCostsKES) |>
  
  # normalize all numeric variables
  step_normalize(GrossFamilyIncome, PovertyProbabilityIndex, NumberOfDependents, ProgramCostsKES)
  
# Create the workflow
multinom_workflow <- 
  workflow() |>
  add_model(multinom_reg_keras_spec) |> 
  add_recipe(multinom_recipe)

# train model
# multinom_fit <- 
#   multinom_workflow |>
#   fit(data = train_data)

```

### Model Fitting

### Model Diagnostics

### Band Prediction

# Conclusion
